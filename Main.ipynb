{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #0000FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "  <h1>Team Info</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Name: Turbo Adventure\n",
    "## Team Members: Akshay, Louis, Reno, Gabrijel\n",
    "## Kaggle Usernames: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #0000FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "  <h1>1 Feature Engineering</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from librosa.feature import rhythm  \n",
    "from IPython.display import display\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT, 2024, Prompt 1: \"welke geluidsfeatures zijn er voor clustering van geluidsfragmenten\"\n",
    "# ChatGPT, 2024, Prompt 2: \"geef per feature aan welke library ik daarvoor kan gebruiken\"\n",
    "# ChatGPT, 2024, Prompt 3: \"laat voorbeeld code zien hoe deze features worden toegepast op een geluidsfragment, en vervolgens in een df wordt gezet\"\n",
    "# ChatGPT, 2024, Prompt 3: \"hoe pas ik oop toe op deze code\"\n",
    "# Link: https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9\n",
    "\n",
    "class AudioFeatureExtractor:\n",
    "    \"\"\"\n",
    "    A class to extract audio features from all .wav files in a given folder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, audio_folder):\n",
    "        \"\"\"\n",
    "        Initialize the AudioFeatureExtractor with the folder containing audio files.\n",
    "        \"\"\"\n",
    "        self.audio_folder = audio_folder\n",
    "        self.features_list = []\n",
    "\n",
    "    def process_audio_files(self):\n",
    "        \"\"\"\n",
    "        Iterate through all .wav files in the folder and extract features.\n",
    "        \"\"\"\n",
    "        for file_name in os.listdir(self.audio_folder):\n",
    "            if file_name.endswith(\".wav\"):  # Only process .wav files\n",
    "                file_path = os.path.join(self.audio_folder, file_name)\n",
    "                self._extract_features(file_name, file_path)\n",
    "\n",
    "    def _extract_features(self, file_name, file_path):\n",
    "        \"\"\"\n",
    "        Extract features from a single audio file and add them to the features list.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Compute features\n",
    "            features = {\n",
    "                \"File Name\": file_name,\n",
    "                \"Zero Crossing Rate\": np.mean(librosa.feature.zero_crossing_rate(y)[0]),\n",
    "                \"RMS Amplitude\": np.mean(librosa.feature.rms(y=y)[0]),\n",
    "                \"Spectral Centroid\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)[0]),\n",
    "                \"Spectral Bandwidth\": np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]),\n",
    "                \"Spectral Roll-Off\": np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)[0]),\n",
    "                \"Spectral Flatness\": np.mean(librosa.feature.spectral_flatness(y=y)[0]),\n",
    "                \"MFCC1\": np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)[0]),\n",
    "                \"MFCC2\": np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)[1]),\n",
    "                \"Chroma Features\": np.mean(librosa.feature.chroma_cqt(y=y, sr=sr)),\n",
    "                \"Tempo (BPM)\": rhythm.tempo(y=y, sr=sr)[0],\n",
    "            }\n",
    "\n",
    "            # Append features to the list\n",
    "            self.features_list.append(features)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "    def get_features_dataframe(self):\n",
    "        \"\"\"\n",
    "        Convert the features list to a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Extract Features & Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Zero Crossing Rate</th>\n",
       "      <th>RMS Amplitude</th>\n",
       "      <th>Spectral Centroid</th>\n",
       "      <th>Spectral Bandwidth</th>\n",
       "      <th>Spectral Roll-Off</th>\n",
       "      <th>Spectral Flatness</th>\n",
       "      <th>MFCC1</th>\n",
       "      <th>MFCC2</th>\n",
       "      <th>Chroma Features</th>\n",
       "      <th>Tempo (BPM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m00003.wav</td>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>2254.606986</td>\n",
       "      <td>2071.028440</td>\n",
       "      <td>4381.532206</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>-82.511116</td>\n",
       "      <td>97.341721</td>\n",
       "      <td>0.571940</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m00012.wav</td>\n",
       "      <td>0.178108</td>\n",
       "      <td>0.217475</td>\n",
       "      <td>2908.300131</td>\n",
       "      <td>2286.252592</td>\n",
       "      <td>5405.816551</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>-1.913298</td>\n",
       "      <td>72.686157</td>\n",
       "      <td>0.533881</td>\n",
       "      <td>103.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m00013.wav</td>\n",
       "      <td>0.123423</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>1952.607933</td>\n",
       "      <td>1865.996047</td>\n",
       "      <td>3779.909832</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>-287.603699</td>\n",
       "      <td>101.758171</td>\n",
       "      <td>0.385155</td>\n",
       "      <td>95.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m00043.wav</td>\n",
       "      <td>0.126073</td>\n",
       "      <td>0.100411</td>\n",
       "      <td>2384.634958</td>\n",
       "      <td>2072.759900</td>\n",
       "      <td>4584.132502</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>-120.147491</td>\n",
       "      <td>91.317215</td>\n",
       "      <td>0.557109</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m00044.wav</td>\n",
       "      <td>0.052088</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>790.507005</td>\n",
       "      <td>900.409298</td>\n",
       "      <td>1159.412273</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-437.604401</td>\n",
       "      <td>170.931534</td>\n",
       "      <td>0.332215</td>\n",
       "      <td>107.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>m00971.wav</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>1525.791709</td>\n",
       "      <td>1588.217850</td>\n",
       "      <td>2733.184659</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>-246.158646</td>\n",
       "      <td>149.428665</td>\n",
       "      <td>0.414986</td>\n",
       "      <td>107.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>m00973.wav</td>\n",
       "      <td>0.161797</td>\n",
       "      <td>0.259782</td>\n",
       "      <td>3669.810467</td>\n",
       "      <td>3295.063699</td>\n",
       "      <td>7876.372739</td>\n",
       "      <td>0.088763</td>\n",
       "      <td>-8.573005</td>\n",
       "      <td>54.295788</td>\n",
       "      <td>0.475779</td>\n",
       "      <td>129.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>m00988.wav</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>0.240724</td>\n",
       "      <td>3941.417697</td>\n",
       "      <td>3361.641125</td>\n",
       "      <td>8260.423162</td>\n",
       "      <td>0.089354</td>\n",
       "      <td>-56.153061</td>\n",
       "      <td>36.448502</td>\n",
       "      <td>0.480985</td>\n",
       "      <td>103.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>m00991.wav</td>\n",
       "      <td>0.044217</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>983.971719</td>\n",
       "      <td>1404.408040</td>\n",
       "      <td>1853.129475</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-406.846680</td>\n",
       "      <td>163.081345</td>\n",
       "      <td>0.235405</td>\n",
       "      <td>117.453835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>m00995.wav</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.066664</td>\n",
       "      <td>1253.032399</td>\n",
       "      <td>1371.258170</td>\n",
       "      <td>2292.769869</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-223.187332</td>\n",
       "      <td>163.253967</td>\n",
       "      <td>0.344185</td>\n",
       "      <td>151.999081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      File Name  Zero Crossing Rate  RMS Amplitude  Spectral Centroid  \\\n",
       "0    m00003.wav            0.120116       0.136221        2254.606986   \n",
       "1    m00012.wav            0.178108       0.217475        2908.300131   \n",
       "2    m00013.wav            0.123423       0.029083        1952.607933   \n",
       "3    m00043.wav            0.126073       0.100411        2384.634958   \n",
       "4    m00044.wav            0.052088       0.018833         790.507005   \n",
       "..          ...                 ...            ...                ...   \n",
       "100  m00971.wav            0.091590       0.038885        1525.791709   \n",
       "101  m00973.wav            0.161797       0.259782        3669.810467   \n",
       "102  m00988.wav            0.167480       0.240724        3941.417697   \n",
       "103  m00991.wav            0.044217       0.017138         983.971719   \n",
       "104  m00995.wav            0.071629       0.066664        1253.032399   \n",
       "\n",
       "     Spectral Bandwidth  Spectral Roll-Off  Spectral Flatness       MFCC1  \\\n",
       "0           2071.028440        4381.532206           0.009073  -82.511116   \n",
       "1           2286.252592        5405.816551           0.026373   -1.913298   \n",
       "2           1865.996047        3779.909832           0.002211 -287.603699   \n",
       "3           2072.759900        4584.132502           0.008830 -120.147491   \n",
       "4            900.409298        1159.412273           0.000153 -437.604401   \n",
       "..                  ...                ...                ...         ...   \n",
       "100         1588.217850        2733.184659           0.006208 -246.158646   \n",
       "101         3295.063699        7876.372739           0.088763   -8.573005   \n",
       "102         3361.641125        8260.423162           0.089354  -56.153061   \n",
       "103         1404.408040        1853.129475           0.000302 -406.846680   \n",
       "104         1371.258170        2292.769869           0.000566 -223.187332   \n",
       "\n",
       "          MFCC2  Chroma Features  Tempo (BPM)  \n",
       "0     97.341721         0.571940   135.999178  \n",
       "1     72.686157         0.533881   103.359375  \n",
       "2    101.758171         0.385155    95.703125  \n",
       "3     91.317215         0.557109   135.999178  \n",
       "4    170.931534         0.332215   107.666016  \n",
       "..          ...              ...          ...  \n",
       "100  149.428665         0.414986   107.666016  \n",
       "101   54.295788         0.475779   129.199219  \n",
       "102   36.448502         0.480985   103.359375  \n",
       "103  163.081345         0.235405   117.453835  \n",
       "104  163.253967         0.344185   151.999081  \n",
       "\n",
       "[105 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ChatGPT, 2024, Prompt 1: \"welke geluidsfeatures zijn er voor clustering van geluidsfragmenten\"\n",
    "# ChatGPT, 2024, Prompt 2: \"geef per feature aan welke library ik daarvoor kan gebruiken\"\n",
    "# ChatGPT, 2024, Prompt 3: \"laat voorbeeld code zien hoe deze features worden toegepast op een geluidsfragment, en vervolgens in een df wordt gezet\"\n",
    "# ChatGPT, 2024, Prompt 3: \"hoe pas ik oop toe op deze code\"\n",
    "# Link: https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9\n",
    "\n",
    "# Define the folder containing audio files\n",
    "audio_folder_path = r\"muziek-genre-clustering-24-25\\unlabeled\"\n",
    "\n",
    "# Create an instance of the AudioFeatureExtractor class\n",
    "extractor = AudioFeatureExtractor(audio_folder=audio_folder_path)\n",
    "\n",
    "# Process the audio files\n",
    "extractor.process_audio_files()\n",
    "\n",
    "# Get the features as a DataFrame\n",
    "audio_features_df = extractor.get_features_dataframe()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(audio_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Features Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate\n",
    "The zero crossing rate is the rate at which a signal changes from positive to negative or vice versa and thus crossing the zero line in a given period. (11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Amplitude\n",
    "The RMS Amplitude is the Root Mean Square of all the measured amplitudes of a signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Centroid\n",
    "The Spectral Centroid indicates where the center of mass of the spectrum is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Bandwidth\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Spectral Bandwidth**\n",
    "#### **What it means:**\n",
    "Spectral bandwidth measures the spread or width of the frequency spectrum. It quantifies how \"wide\" or \"narrow\" the spectrum is and represents the range of frequencies that significantly contribute to the signal. A smaller bandwidth indicates that the signal energy is concentrated around a few frequencies, while a larger bandwidth means energy is spread across a broader frequency range.\n",
    "\n",
    "#### **How it's calculated:**\n",
    "- **Definition**: The spectral bandwidth is typically the standard deviation (or variance) of the power spectrum around its centroid (mean frequency).\n",
    "- **Formula**:\n",
    "\n",
    "$$\n",
    "\\text{Bandwidth} = \\sqrt{\\frac{\\sum (f - f_c)^2 \\cdot S(f)}{\\sum S(f)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( f \\): frequency  \n",
    "- \\( f_c \\): spectral centroid  \n",
    "- \\( S(f) \\): spectral power (magnitude squared of the spectrum)  \n",
    "\n",
    "#### **What it signifies:**\n",
    "- A **low bandwidth** suggests the signal has tonal or harmonic content, like a pure tone or music.\n",
    "- A **high bandwidth** suggests noise-like signals or signals with many different frequency components.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Roll-Off\n",
    "### **2. Spectral Roll-Off**\n",
    "#### **What it means:**\n",
    "Spectral roll-off indicates the frequency below which a certain percentage (e.g., 85%) of the total spectral energy is concentrated. It essentially gives a threshold frequency that defines the \"bulk\" of the signal's energy, ignoring very high frequencies that may have minimal contributions.\n",
    "\n",
    "#### **How it's calculated:**\n",
    "- **Definition**: It is the frequency \\( f_r \\) where a certain proportion \\( p \\) (commonly 85%) of the total power in the spectrum lies below that frequency.\n",
    "- **Formula**:\n",
    "\n",
    "$$\n",
    "\\sum_{f=0}^{f_r} S(f) \\geq p \\cdot \\sum_{f=0}^{f_{\\text{max}}} S(f)\n",
    "$$\n",
    "\n",
    "#### **What it signifies:**\n",
    "- A **low roll-off frequency** suggests that most of the signal's energy is concentrated in the lower frequencies (e.g., a bass-heavy signal).\n",
    "- A **high roll-off frequency** suggests significant energy in higher frequencies (e.g., signals with sharp transients or high harmonics).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Flatness\n",
    "### **3. Spectral Flatness**\n",
    "#### **What it means:**\n",
    "Spectral flatness measures how \"flat\" or \"peaky\" a spectrum is. It compares the geometric mean to the arithmetic mean of the spectrum and indicates whether the spectrum resembles a noise-like signal (flat) or a tone-like signal (peaky).\n",
    "\n",
    "#### **How it's calculated:**\n",
    "- **Definition**: It is the ratio of the geometric mean to the arithmetic mean of the power spectrum.\n",
    "- **Formula**:\n",
    "\n",
    "$$\n",
    "\\text{Flatness} = \\frac{\\left( \\prod_{f=0}^{f_{\\text{max}}} S(f) \\right)^{1/N}}{\\frac{1}{N} \\sum_{f=0}^{f_{\\text{max}}} S(f)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( S(f) \\): spectral power at frequency \\( f \\)  \n",
    "- \\( N \\): total number of frequency bins in the spectrum  \n",
    "\n",
    "#### **What it signifies:**\n",
    "- A **flat spectrum** (value near 1) suggests white noise or a similar signal where energy is evenly distributed across frequencies.\n",
    "- A **low flatness** (value near 0) indicates the presence of dominant tonal components, such as those in harmonic sounds or pure tones.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Interpretations**:\n",
    "\n",
    "| **Feature**         | **High Value Indicates**                          | **Low Value Indicates**                       |\n",
    "|----------------------|--------------------------------------------------|-----------------------------------------------|\n",
    "| **Spectral Bandwidth** | Broad, noisy, or transient signals              | Tonal, harmonic, or narrow-band signals       |\n",
    "| **Spectral Roll-Off** | Energy in higher frequencies                     | Energy concentrated in lower frequencies      |\n",
    "| **Spectral Flatness** | Noise-like, evenly distributed spectrum          | Tonal, peaky spectrum                         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFCCs\n",
    "### **X. MFCCs**\n",
    "#### **What it means:**\n",
    "\n",
    "MFCCs (Mel-frequency Cepstral Coefficients) describe the short-term power spectrums of audio, which explain the most noticeable attributes of verbal communication. Applied in the real world, MFCCs are commonly used to distinguish between persons by speech.\n",
    "\n",
    "#### **How it's calculated:**\n",
    "\n",
    "There is not only one single way to caculate MFCCs, but usually these steps are followed (GeeksforGeeks, 2024):\n",
    "\n",
    "- Pre-emphasize the signal: Stabilizing the spectrum by raising the frequency\n",
    "- Framing: Splitting the audio into more, but overlapping chunks\n",
    "- Windowing: A window function is used to mitigate the edge effect of framing\n",
    "- FFT (Fast Fourier Transform): The Fourier Transform is calculated by transforming the time domain frames to frequency domain frames in order to get the spectral representations\n",
    "- Mel-filterbank: The Mel-filterbank seperates the spectral representations into Frequency Bands based on Mel-scale. Then filters extract the energy level and the more crucial frequencies get prioritized\n",
    "- Logarithm: The logarithm is calculated to recieve a more accurate representation of the loudness\n",
    "- DCT: After minimizing the duplicate coefficients, the Mel-frequency Cepstral Coefficients are finally the result\n",
    "\n",
    "The rows of the MFCC matrix capture these features:\n",
    "- MFCC1:\n",
    "- MFCC2:\n",
    "\n",
    "#### **What it signifies:**\n",
    "- A **low MFCC1**\n",
    "- A **high MFCC1**\n",
    "- A **low MFCC2**\n",
    "- A **high MFCC2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Features\n",
    "\n",
    "Chroma features are a widely used representation in music analysis and processing, as they capture the harmonic content of a piece by summarizing the energy distribution across the twelve pitch classes (C, C#, D, etc.) within an octave. This abstraction allows for the comparison of tonal structures irrespective of the actual octave in which a note is played, making it particularly robust to changes in pitch and instrumentation. Müller (2015) highlights the effectiveness of chroma features in tasks such as chord recognition, genre classification, and music retrieval.\n",
    "\n",
    "#### How do chroma features work?\n",
    "The process of extracting chroma features involves the following steps:\n",
    "1. **Frame segmentation:** The audio signal is divided into small, overlapping time frames.\n",
    "2. **Frequency transformation:** Each frame undergoes a **Short-Time Fourier Transform (STFT)**, converting the audio from the time domain to the frequency domain.\n",
    "3. **Pitch class aggregation:** For each frequency bin, the energy is mapped to its corresponding pitch class (e.g., C, C#, D), and the values are summed across all octaves. This results in a 12-dimensional chroma vector for each frame (Tzanetakis & Cook, 2002).\n",
    "\n",
    "This process creates a \"fingerprint\" of the music's harmonic structure, enabling analysis that is invariant to timbral and octave shifts. For example, a melody played on a piano or a guitar will have a similar chroma representation if the notes are the same (Müller, 2015).\n",
    "\n",
    "#### Example: Computing Chroma Features\n",
    "Let’s take a sine wave with a frequency of 440 Hz (A4 note) sampled at 44.1 kHz:\n",
    "1. Perform an STFT to compute the frequency spectrum of the audio signal.\n",
    "2. Identify that 440 Hz corresponds to the pitch class \"A.\"\n",
    "3. Assign all energy to the pitch class \"A\" in the chroma vector, while all other pitch classes remain zero.\n",
    "\n",
    "The resulting chroma vector might look like this:\n",
    "`[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`  \n",
    "Here, the 8th position (A) has a value of 1, indicating that \"A\" is the dominant pitch class.\n",
    "\n",
    "#### Applications and importance\n",
    "- **Chord recognition:** Chroma features are widely used to detect harmonic progressions, such as identifying the chord sequence in a song (Müller, 2015).\n",
    "- **Genre classification:** These features are particularly useful for distinguishing genres with complex harmonic structures, like jazz or classical music (Tzanetakis & Cook, 2002).\n",
    "- **Music similarity and retrieval:** By focusing on tonal content, chroma features can help identify similar tracks or cover versions of songs (Wikipedia contributors, n.d.-a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo (BPM)\n",
    "\n",
    "Tempo refers to the speed or pace of a piece of music, measured in beats per minute (BPM). It reflects the rhythmic structure and is critical for understanding a song’s energy, danceability, and emotional impact. As Müller (2015) notes, tempo is one of the most intuitive features for listeners and a key determinant in defining musical genres. Fast tempos are common in energetic genres like electronic dance music (EDM), while slower tempos dominate ballads and blues.\n",
    "\n",
    "#### How is tempo calculated?\n",
    "The process of tempo extraction typically involves:\n",
    "1. **Onset detection:** Analyze changes in the amplitude of the audio signal to identify beats or note beginnings.\n",
    "2. **Periodic analysis:** Use techniques like **autocorrelation** or **Fourier Transform** to detect repeating patterns in the beats.\n",
    "3. **Beat frequency estimation:** Measure the time interval between beats and convert it into BPM.\n",
    "\n",
    "#### Example: Estimating Tempo\n",
    "Consider an audio track where beats occur every 0.5 seconds:\n",
    "1. Measure the time interval between beats: \\( T = 0.5 \\, \\text{s} \\).\n",
    "2. Calculate the tempo using the formula:  \n",
    "   $$\\text{BPM} = \\frac{60}{T} = \\frac{60}{0.5} = 120 \\, \\text{BPM}.$$\n",
    "\n",
    "This indicates the track has a tempo of 120 BPM, which is typical for many pop and dance tracks (Tzanetakis & Cook, 2002).\n",
    "\n",
    "#### Applications and importance\n",
    "- **Genre differentiation:** Tempo is a distinguishing feature in many genres, such as EDM (typically 120–140 BPM) versus ballads (50–70 BPM) (Müller, 2015).\n",
    "- **Music recommendation:** Tracks with similar tempos are often grouped together in playlists for specific activities, like workouts or relaxation (Wikipedia contributors, n.d.-b).\n",
    "- **Rhythmic analysis:** Provides insights into the overall \"feel\" or \"groove\" of a piece, which is essential for understanding its style and energy (Tzanetakis & Cook, 2002)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #0000FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "  <h1>2 Unsupervised Learning</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 DBSCAN\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm introduced by Ester et al. (1996). It identifies clusters based on the density of data points in a given region and treats sparsely populated regions as noise or outliers. Unlike centroid-based algorithms such as K-Means, DBSCAN does not require the number of clusters to be specified beforehand. Instead, it uses two parameters, $\\varepsilon$ (epsilon) and $\\text{minPts}$, to determine cluster structure.\n",
    "\n",
    "This algorithm is particularly suitable for datasets where clusters exhibit irregular shapes and varying densities. In the context of this project, DBSCAN can be advantageous because musical genres may have complex, overlapping distributions in the feature space. Furthermore, DBSCAN’s ability to detect noise could help exclude outliers or unusual audio fragments that do not belong to any genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Algorithmic Principles**\n",
    "\n",
    "DBSCAN uses the following key concepts to identify clusters:\n",
    "\n",
    "1. **Neighborhood definition:**\n",
    "   For a point \\(p\\), its \\(\\varepsilon\\)-neighborhood is defined as:\n",
    "   \\[\n",
    "   N_{\\varepsilon}(p) = \\{q \\in D \\,|\\, \\|p - q\\| \\leq \\varepsilon\\}\n",
    "   \\]\n",
    "   Here, \\(D\\) represents the dataset, and \\(\\|p - q\\|\\) is the distance between points \\(p\\) and \\(q\\) (commonly Euclidean distance).\n",
    "\n",
    "2. **Core points:**\n",
    "   A point \\(p\\) is classified as a core point if it satisfies:\n",
    "   \\[\n",
    "   |N_{\\varepsilon}(p)| \\geq \\text{minPts}\n",
    "   \\]\n",
    "\n",
    "3. **Border points:**\n",
    "   A point \\(p\\) is classified as a border point if it lies within the \\(\\varepsilon\\)-neighborhood of a core point but does not itself satisfy the core point condition.\n",
    "\n",
    "4. **Noise points:**\n",
    "   Points that are neither core points nor reachable from any core points are classified as noise.\n",
    "\n",
    "5. **Cluster formation:**\n",
    "   Clusters are formed by expanding the neighborhoods of core points. A core point can connect to other core points and border points, creating dense regions that define a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Algorithm Steps**\n",
    "\n",
    "1. Begin with an unvisited point \\(p\\).\n",
    "2. Determine if \\(p\\) is a core point:\n",
    "   - If \\(p\\) is a core point, start a new cluster.\n",
    "   - Include all points within the \\(\\varepsilon\\)-neighborhood of \\(p\\) in the cluster.\n",
    "   - Recursively check all core points in the neighborhood and add their connected points.\n",
    "3. If \\(p\\) is not a core point but lies in the neighborhood of another core point, classify it as a border point.\n",
    "4. If \\(p\\) is neither a core nor a border point, classify it as noise.\n",
    "5. Repeat until all points in the dataset have been visited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Advantages and Limitations**\n",
    "\n",
    "**Advantages:**\n",
    "- DBSCAN can identify clusters of arbitrary shapes, which is beneficial when analyzing datasets with irregular patterns, such as musical genres.\n",
    "- The algorithm automatically detects noise and excludes it from the clustering process.\n",
    "- There is no need to predefine the number of clusters, making it suitable for exploratory tasks.\n",
    "\n",
    "**Limitations:**\n",
    "- The algorithm is sensitive to the choice of \\(\\varepsilon\\) and \\(\\text{minPts}\\), and inappropriate parameter values can lead to over-clustering or under-clustering.\n",
    "- DBSCAN struggles with datasets that contain clusters of varying densities, as this can affect neighborhood detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Application Example**\n",
    "\n",
    "This example demonstrates the application of DBSCAN on a two-dimensional synthetic dataset that mimics the feature space of audio fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "dense_cluster = np.random.randn(100, 2) * 0.5 + [2, 2]\n",
    "sparse_cluster = np.random.randn(50, 2) * 0.8 + [-2, -2]\n",
    "noise = np.random.uniform(-6, 6, (20, 2))\n",
    "data = np.vstack([dense_cluster, sparse_cluster, noise])\n",
    "\n",
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
    "labels = dbscan.fit_predict(data)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "unique_labels = set(labels)\n",
    "for label in unique_labels:\n",
    "    cluster_points = data[labels == label]\n",
    "    if label == -1:\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], color='red', label='Noise')\n",
    "    else:\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {label}')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "DBSCAN is a suitable algorithm for this project because of its ability to identify clusters of arbitrary shapes and handle noise effectively. Unlike centroid-based methods such as K-Means, DBSCAN does not assume spherical clusters and is well-suited for datasets with irregular patterns (Ester et al., 1996). This flexibility is particularly advantageous when clustering musical genres, as the feature space may exhibit overlapping or complex structures.\n",
    "\n",
    "Moreover, DBSCAN's robustness against noise allows it to exclude outliers from the clustering process, making it effective for detecting unusual or out-of-distribution audio fragments (Pedregosa et al., 2011). However, the algorithm is sensitive to the choice of its parameters ($\\varepsilon$ and $\\text{minPts}$), which require careful tuning based on the dataset's density distribution.\n",
    "\n",
    "Despite these challenges, DBSCAN remains a strong candidate for exploratory clustering in this project due to its adaptability and lack of reliance on predefined cluster counts. Future steps should include parameter optimization and comparison with other clustering methods to assess its performance comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Gaussian Mixture Models (GMM)\n",
    "\n",
    "GMM is a soft clustering model, that assigns each observation a probability of belonging to a specific cluster. In this algorithm each cluster is represented by a normal (gaussian) distribution with the mean and covariance matrix as metrics.\n",
    "\n",
    "This model utilizes the Expectation-Maximization method, which is split into the following phases:\n",
    "\n",
    "- Initialize phase: The mean, the covariance matrix and the mixing coefficients of every gaussian distribution (cluster) are assumed.\n",
    "\n",
    "- Expectation phase: The observations are assigned to gaussian distributions (clusters) based on the calculated probability, that they belong to them.\n",
    "\n",
    "- Maximization phase: The mean, the covariance matrix and the mixing coefficients of every gaussian distribution (cluster) are calculated with the assigned observations. \n",
    "\n",
    "Then the Expectation and Maximization phase are reiterated, until the model can not be notably improved anymore.\n",
    "\n",
    "To calculate the probability, that an observation belongs to a cluster, the following probability density function (pdf) formula is used (What Is Gaussian Mixture Model | Deepchecks, 2023):\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\text{pdf}(x) = \\sum_{k=1}^{K} \\pi_k \\cdot N(x|\\mu_k, \\Sigma_k)\n",
    "$$\n",
    "\n",
    "- $\\pi_k$ = Mixing coefficient\n",
    "- $\\mu_k$ = Mean vector  \n",
    "- $\\Sigma_k$ = Covariance matrix\n",
    "- $N(x|\\mu_k, \\Sigma_k)$ = Probability density function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #0000FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "  <h1>3 Findings and Conclusion</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #0000FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "  <h1>4 Reference List</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Sources\n",
    "\n",
    "* ChatGPT, 2024, Prompt 1: \"welke geluidsfeatures zijn er voor clustering van geluidsfragmenten\", (https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9)\n",
    "\n",
    "* ChatGPT, 2024, Prompt 2: \"geef per feature aan welke library ik daarvoor kan gebruiken\", (https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9)\n",
    "\n",
    "* ChatGPT, 2024, Prompt 3: \"laat voorbeeld code zien hoe deze features worden toegepast op een geluidsfragment, en vervolgens in een df wordt gezet\", (https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9)\n",
    "* ChatGPT, 2024, Prompt 4: \"hoe pas ik oop toe op deze code\", (https://chatgpt.com/share/677ee38d-fb54-8001-a50a-9856d52e22c9)\n",
    "* GeeksforGeeks. (2024, 26. Juni). Melfrequency Cepstral Coefficients (MFCC) for Speech Recognition. GeeksforGeeks. https://www.geeksforgeeks.org/mel-frequency-cepstral-coefficients-mfcc-for-speech-recognition/\n",
    "* What is Gaussian Mixture Model | Deepchecks. (2023, 23. Januar). Deepchecks. https://www.deepchecks.com/glossary/gaussian-mixture-model/\n",
    "- Wikipedia contributors. (n.d.-a). Chroma feature. In *Wikipedia*. Retrieved January 12, 2025, from  \n",
    "   [https://en.wikipedia.org/wiki/Chroma_feature](https://en.wikipedia.org/wiki/Chroma_feature)\n",
    "\n",
    "-  Wikipedia contributors. (n.d.-b). Tempo. In *Wikipedia*. Retrieved January 12, 2025, from  \n",
    "   [https://en.wikipedia.org/wiki/Tempo](https://en.wikipedia.org/wiki/Tempo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literature\n",
    "\n",
    "- Ester, M., Kriegel, H.-P., Sander, J., & Xu, X. (1996). A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. *Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD)*, 226–231.  \n",
    "  Retrieved from [https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf](https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf)\n",
    "\n",
    "- Müller, M. (2015). *Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications*. Springer Verlag.  \n",
    "   This comprehensive textbook covers key topics in music information retrieval, including chroma features and tempo analysis.\n",
    "\n",
    "- Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, É. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825–2830.  \n",
    "  Retrieved from [https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html)\n",
    "\n",
    "-  Tzanetakis, G., & Cook, P. (2002). Musical genre classification of audio signals. *IEEE Transactions on Speech and Audio Processing*, 10(5), 293–302.  \n",
    "   DOI: [10.1109/TSA.2002.800560](https://doi.org/10.1109/TSA.2002.800560)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
